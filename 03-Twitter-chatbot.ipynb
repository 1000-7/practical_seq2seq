{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate Seq2Seq Wrapper with twitter chat log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# preprocessed data\n",
    "from datasets.twitter import data\n",
    "import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data from pickle and npy files\n",
    "metadata, idx_q, idx_a = data.load_data(PATH='datasets/twitter/')\n",
    "(trainX, trainY), (testX, testY), (validX, validY) = data_utils.split_dataset(idx_q, idx_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters \n",
    "xseq_len = trainX.shape[-1]\n",
    "yseq_len = trainY.shape[-1]\n",
    "batch_size = 16\n",
    "xvocab_size = len(metadata['idx2w'])  \n",
    "yvocab_size = xvocab_size\n",
    "emb_dim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seq2seq_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'seq2seq_wrapper' from '/home/suriya/_/tf/tf-seq2seq-wrapper/seq2seq_wrapper.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(seq2seq_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<log> Building Graph </log>"
     ]
    }
   ],
   "source": [
    "model = seq2seq_wrapper.Seq2Seq(xseq_len=xseq_len,\n",
    "                               yseq_len=yseq_len,\n",
    "                               xvocab_size=xvocab_size,\n",
    "                               yvocab_size=yvocab_size,\n",
    "                               ckpt_path='ckpt/twitter/',\n",
    "                               emb_dim=emb_dim,\n",
    "                               num_layers=3\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_batch_gen = data_utils.rand_batch_gen(validX, validY, 256)\n",
    "train_batch_gen = data_utils.rand_batch_gen(trainX, trainY, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<log> Training started </log>\n",
      "\n",
      "Model saved to disk at iteration #500\n",
      "val   loss : 3.370399\n",
      "Interrupted by user at iteration 565\n"
     ]
    }
   ],
   "source": [
    "sess = model.train(train_batch_gen, val_batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = model.restore_last_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 20)\n"
     ]
    }
   ],
   "source": [
    "input_ = val_batch_gen.__next__()[0]\n",
    "output = model.predict(sess, input_)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q : [it is finally sweater weather and i am so happy]; a : [i love you so much]\n",
      "q : [thats not what i meant]; a : [i dont know what i said]\n",
      "q : [anyone have unk unk or recipe blog recommendations in english thank you]; a : [i will be there]\n",
      "q : [the graphic novel club is the unk ]; a : [i was in the same time]\n",
      "q : [congrats guys  awesome unk well done ]; a : [thank you ]\n",
      "q : [sounds unk]; a : [i dont know what i was thinking about it]\n",
      "q : [my lil sis was in his latest video and i kept texting her like show him my ig lmao]; a : [i was so happy for that]\n",
      "q : [i feel attacked by this photo]; a : [i love you and i am so excited to see you]\n",
      "q : [this is wrong and shameful and the worst thing ive read all week]; a : [i love you and i am so happy to see you]\n",
      "q : [awesome thanks  looking unk to connecting]; a : [thank you for the shout out]\n",
      "q : [a1 especially today expect a unk customer experience across all channels]; a : [you can be in the city]\n",
      "q : [we cant change the date for unk lol]; a : [i dont know what i was doing]\n",
      "q : [its a great twitch unk game hard as heck and requires strategy i bet is good at it]; a : [i love it]\n",
      "q : [extremely excited that are playing the unk union unk in december tickets on sale now]; a : [i wish i was there]\n",
      "q : [just unk through]; a : [i love you]\n",
      "q : [bernie was my guy sorry i do not know what unk is]; a : [i dont know what he said]\n",
      "q : [tonight finna be interesting]; a : [i am so excited to see you]\n",
      "q : [congrats to our unk unk on being promoted as first muslim unk in the nypd]; a : [thank you for the support]\n",
      "q : [just got a unk chicken that if didnt order its lie]; a : [i dont know what you mean]\n",
      "q : [im pretending today is not a high of unk  and making my moms famous unk  ]; a : [i am so happy for you]\n",
      "q : [i already threw that shit away guess im fucked now ]; a : [i dont know what i was talking about]\n",
      "q : [now he your bff t lmao]; a : [i love you ]\n",
      "q : [i love how the ear is sticking out of the cap]; a : [i know i was just thinking about it]\n",
      "q : [at this point i feel its sad and i should just stop responding clearly im not getting anywhere]; a : [i dont know what i meant about you]\n",
      "q : [congratulations on being named a unk proud of you fam]; a : [thank you so much]\n",
      "q : [let the next couple of years unk and take notes well see it happen very very soon]; a : [thanks for the shout out]\n",
      "q : [unk unk has been unk supporting the unk of alicia machado]; a : [i am not sure what you are doing]\n",
      "q : [no rest for the brilliant ]; a : [i was thinking about this]\n",
      "q : [unk can it pull from fb because otherwise thats so much effort]; a : [i dont know how to get it]\n",
      "q : [listen to your heart]; a : [i was so happy to see you]\n",
      "q : [thank you for an amazing night and show cant believe it was already 1 week ago ]; a : [great to see you guys]\n",
      "q : [i dont understand s problem horizon 3 is looking great]; a : [i am not sure what you are]\n",
      "q : [a red dot also means record in video language thank you for asking]; a : [great to meet you and i have a great time]\n",
      "q : [ill be with some friends we welcome their opposition]; a : [i dont know what you are talking about]\n",
      "q : [im bummed lol oh well  next time for sure]; a : [lol i dont know what i was talking about]\n",
      "q : [gotta bring more than the double ps baby]; a : [i was thinking of the same time]\n",
      "q : [5 unk unk more unk for u the unk will go well with unk]; a : [i dont know how to do that]\n",
      "q : [read about an unk was just about to ask u allah unk unk]; a : [i dont know what i meant to say that]\n",
      "q : [you unk need to stop being so hysterical about this]; a : [i am not sure what you are talking about]\n",
      "q : [both of those assholes covered the jets at one point]; a : [i dont know what they were talking about]\n",
      "q : [meanwhile im trying to keep up with you]; a : [you dont know what you mean]\n",
      "q : [correction jeans  rain are unk]; a : [i am so excited to see you there]\n",
      "q : [yeah but maybe in a guy who has some good ideas how come i am coo with everyone]; a : [i dont know what you are]\n",
      "q : [any word on volunteer needs how can we help]; a : [will be there]\n",
      "q : [me because all my friends are in relationships]; a : [i am so sorry for you]\n",
      "q : [youre her phone to the toilet]; a : [i dont know what she said]\n",
      "q : [getting ready for v unk amp unk of os unk unk unk live from cam unk unk]; a : [i love you and i love you]\n",
      "q : [a new chapter begins together is coming to unk]; a : [                   ]\n",
      "q : [ thanks for the assist tonight ill get you a beer this week]; a : [i will be there for you]\n",
      "q : [thanks chris christie]; a : [i am so proud of her]\n"
     ]
    }
   ],
   "source": [
    "replies = []\n",
    "for ii, oi in zip(input_.T, output):\n",
    "    q = data_utils.decode(sequence=ii, lookup=metadata['idx2w'], separator=' ')\n",
    "    decoded = data_utils.decode(sequence=oi, lookup=metadata['idx2w'], separator=' ').split(' ')\n",
    "    if decoded.count('unk') == 0:\n",
    "        if decoded not in replies:\n",
    "            print('q : [{0}]; a : [{1}]'.format(q, ' '.join(decoded)))\n",
    "            replies.append(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
